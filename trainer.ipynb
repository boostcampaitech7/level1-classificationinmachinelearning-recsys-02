{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"real_final_df.csv\"\n",
    "model_name = \"LGBM\" # LGBM/XGB/RF/CatBoost/FCLGBM/SVM\n",
    "seve_name = \"LGBM_hpt_Bayes.csv\"\n",
    "split_type = \"randomcv\" # random/time/randomcv\n",
    "drop_colunm = [\"target\", \"ID\", \"dir_prob_ts\"]\n",
    "target_colunm = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_params(model_name):\n",
    "    # lgbm params\n",
    "    lgbm_params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_class\": 4,\n",
    "        \"num_leaves\": 97,\n",
    "        \"learning_rate\": 0.015732043600075817,\n",
    "        \"n_estimators\": 52,\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    xgb_params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 4,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"n_estimators\": 100,\n",
    "        \"random_state\": 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    rf_params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": 'sqrt',\n",
    "        \"bootstrap\": True,\n",
    "        \"criterion\": 'gini',\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": 1\n",
    "    }\n",
    "\n",
    "    catboost_params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"depth\": 6,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 100,\n",
    "        \"l2_leaf_reg\": 3,\n",
    "        \"bagging_temperature\": 1,\n",
    "        \"cat_features\": [],\n",
    "        \"loss_function\":'MultiClass'\n",
    "    }\n",
    "    \n",
    "    from utils.focal_loss import focal_loss_lgb\n",
    "    focal_loss = lambda x,y: focal_loss_lgb(x, y, 0.25, 2.0, 4)\n",
    "    fclgbm_params = { \"num_class\":4,\n",
    "            \"objective\": focal_loss,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"num_class\": 4,\n",
    "            \"num_leaves\": 60,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"n_estimators\": 26,\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": 0,\n",
    "    }\n",
    "    svm_params = {\n",
    "        \"C\": 1.0,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"degree\": 3,\n",
    "        \"gamma\": \"scale\",\n",
    "        \"coef0\": 0.0,\n",
    "        \"shrinking\": True,\n",
    "        \"probability\": True,\n",
    "        \"tol\": 1e-3,\n",
    "        \"max_iter\": -1,\n",
    "    }\n",
    "\n",
    "    if model_name == \"LGBM\":\n",
    "        return lgbm_params\n",
    "    elif model_name == \"FCLGBM\":\n",
    "        return fclgbm_params\n",
    "    elif model_name == \"XGB\":\n",
    "        return xgb_params\n",
    "    elif model_name == \"RF\":\n",
    "        return rf_params\n",
    "    elif model_name == \"CatBoost\":\n",
    "        return catboost_params\n",
    "    elif model_name == \"SVM\":\n",
    "        return svm_params\n",
    "    else:\n",
    "        print(\"Invalid model name. (Params)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model_params(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from model.train import train_model, test, final_train_model\n",
    "from dataloader.dataset_load import data_split, _Dataset\n",
    "\n",
    "import csv\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"data\"\n",
    "df: pd.DataFrame = pd.read_csv(os.path.join(data_path, dataset_name))\n",
    "df.columns = df.columns.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수를 제외한 변수를 forwardfill, -999로 결측치 대체\n",
    "_target = df[\"target\"]\n",
    "df = df.ffill().fillna(-999).assign(target = _target)\n",
    "\n",
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cm(y_valid, y_pred):\n",
    "    cm=confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "acc: 0.4544520547945206, auroc: 0.632999753286538\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    }
   ],
   "source": [
    "if split_type != \"randomcv\":\n",
    "    x_train, x_valid, y_train, y_valid = data_split(split_type, train_df, drop_colunm, target_colunm)\n",
    "    train_data, valid_data = _Dataset(model_name, x_train, x_valid, y_train, y_valid)\n",
    "\n",
    "    model, y_pred, accuracy, auroc = train_model(model_name, params, x_train, x_valid, y_train, y_valid, train_data, valid_data)\n",
    "    print(f\"acc: {accuracy}, auroc: {auroc}\")\n",
    "    show_cm(y_valid, y_pred)\n",
    "    submission_df = test(model_name, drop_colunm, model, test_df, submission_df)\n",
    "elif split_type == \"randomcv\":\n",
    "    accuracy_result = 0\n",
    "    auroc_result = 0\n",
    "    x_train_list, x_valid_list, y_train_list, y_valid_list = data_split(split_type, train_df, drop_colunm, target_colunm)\n",
    "    for i in range(5):\n",
    "        x_train = x_train_list[i]\n",
    "        y_train = y_train_list[i]\n",
    "        x_valid = x_valid_list[i]\n",
    "        y_valid = y_valid_list[i]\n",
    "        train_data, valid_data = _Dataset(model_name, x_train, x_valid, y_train, y_valid)\n",
    "\n",
    "        model, y_pred, accuracy, auroc = train_model(model_name, params, x_train, x_valid, y_train, y_valid, train_data, valid_data)\n",
    "        submission_df = test(model_name, drop_colunm, model, test_df, submission_df)\n",
    "        accuracy_result += accuracy\n",
    "        auroc_result += auroc\n",
    "        \n",
    "    accuracy_result /= 5\n",
    "    auroc_result /= 5\n",
    "    accuracy = accuracy_result\n",
    "    auroc = auroc_result\n",
    "    \n",
    "    print(f\"acc: {accuracy}, auroc: {auroc}\")\n",
    "    \n",
    "    # 최종 모델 학습\n",
    "    x_train = train_df.drop(drop_colunm, axis = 1)\n",
    "    y_train = train_df[target_colunm].astype(int)\n",
    "    \n",
    "    model = final_train_model(model_name, params, x_train, y_train, train_data)\n",
    "    \n",
    "    submission_df = test(model_name, drop_colunm, model, test_df, submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(seve_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = (datetime.now()+ timedelta(hours=9)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "f = open('result.csv', 'a', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow([date, accuracy, auroc, dataset_name, model_name, seve_name, split_type, params, 0])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
